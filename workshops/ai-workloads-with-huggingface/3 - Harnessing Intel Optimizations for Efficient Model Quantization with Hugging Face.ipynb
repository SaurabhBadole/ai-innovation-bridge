{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc5ca3da-1b58-4c13-9a14-a20348f6c046",
   "metadata": {},
   "source": [
    "# Harnessing Intel Optimizations for Efficient Model Quantization with Hugging Face\n",
    "<img src=\"https://gestaltit.com/wp-content/uploads/2021/12/quantization-pruning-architecture.jpg\" alt=\"Alt Text\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "## Why Learn About Model Quantization\n",
    "\n",
    "In this developer-focused workshop, we delve into the concept of model quantization and its crucial role in enhancing compute efficiency and reducing latency during inference. Quantization is a process that converts a model from using floating-point numbers to integers, which are computationally less expensive to process. This conversion is essential for deploying models on resource-constrained environments where memory footprint and inference speed are criti\n",
    "\n",
    "<img src=\"https://deci.ai/wp-content/uploads/2023/02/deci-quantization-blog-1b.png\" alt=\"Alt Text\" style=\"width: 800px;\"/>cal.\n",
    "\n",
    "### Understanding the Trade-off\n",
    "\n",
    "While quantization can significantly boost inference speed, it's vital to understand the trade-offs, particularly concerning model accuracy. Sometimes, reducing model size and computational requirements can lead to a decrease in accuracy. This workshop will focus on 'accuracy aware dynamic quantization,' where we aim to balance the trade-offs between speed and accuracy effectively.\n",
    "\n",
    "### Static vs. Dynamic Quantization\n",
    "\n",
    "Before we dive in, let's clarify two types of quantization:\n",
    "- **Static Quantization**: Involves quantizing the weights and activations of the model but requires a calibration step using representative data.\n",
    "- **Dynamic Quantization**: Quantizes the weights but leaves the activations in floating-point. This method is more flexible as it does not require the calibration step, making it suitable for models where input shapes can vary.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll learn how to use the Optimum Intel library to perform dynamic quantization on a Hugging Face model and understand the implications of this process on model performance and efficiency.\n",
    "\n",
    "Let's get started on this journey to make our models faster and more efficient while maintaining their accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f179d-6ef5-46b5-98ee-61fddaa6a549",
   "metadata": {},
   "source": [
    "#### Setting Up the Environment and Initial Imports\n",
    "\n",
    "In this cell, we import essential libraries and tools needed for our quantization task. These include:\n",
    "- `evaluate` and `optimum.intel.INCQuantizer` for evaluating and quantizing our model.\n",
    "- `load_dataset` for loading our evaluation dataset.\n",
    "- `AutoModelForQuestionAnswering` and `AutoTokenizer` for loading our pre-trained model and tokenizer.\n",
    "- `pipeline` for creating a question-answering pipeline.\n",
    "- `neural_compressor.config` components for configuring our quantization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327a9105-a130-4f1a-b15a-5b858b691597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mabout-time==4.2.1\n",
      "accelerate==0.26.1\n",
      "aiohttp==3.9.3\n",
      "aiosignal==1.3.1\n",
      "alive-progress==3.1.5\n",
      "annotated-types==0.6.0\n",
      "anyio==3.7.1\n",
      "asn1crypto @ file:///home/conda/feedstock_root/build_artifacts/asn1crypto_1647369152656/work\n",
      "asttokens @ file:///opt/conda/conda-bld/asttokens_1646925590279/work\n",
      "async-timeout==4.0.3\n",
      "attrs==23.2.0\n",
      "autograd==1.6.2\n",
      "backcall @ file:///home/ktietz/src/ci/backcall_1611930011877/work\n",
      "backoff==2.2.1\n",
      "bcrypt==4.1.2\n",
      "Bottleneck @ file:///opt/conda/conda-bld/bottleneck_1657175564434/work\n",
      "bqplot==0.12.42\n",
      "branca==0.7.1\n",
      "brotlipy @ file:///home/conda/feedstock_root/build_artifacts/brotlipy_1666764672617/work\n",
      "cachetools==5.3.2\n",
      "certifi @ file:///croot/certifi_1690232220950/work/certifi\n",
      "cffi @ file:///home/conda/feedstock_root/build_artifacts/cffi_1671179360775/work\n",
      "chardet @ file:///home/conda/feedstock_root/build_artifacts/chardet_1669990273997/work\n",
      "charset-normalizer @ file:///home/conda/feedstock_root/build_artifacts/charset-normalizer_1678108872112/work\n",
      "chroma-hnswlib==0.7.3\n",
      "chromadb==0.4.15\n",
      "click==8.1.7\n",
      "cloudpickle==3.0.0\n",
      "cma==3.2.2\n",
      "colorama @ file:///home/conda/feedstock_root/build_artifacts/colorama_1666700638685/work\n",
      "coloredlogs==15.0.1\n",
      "colour==0.1.5\n",
      "comm @ file:///croot/comm_1671231121260/work\n",
      "conda==23.3.1\n",
      "conda-package-handling @ file:///home/conda/feedstock_root/build_artifacts/conda-package-handling_1669907009957/work\n",
      "conda_package_streaming @ file:///home/conda/feedstock_root/build_artifacts/conda-package-streaming_1685101166527/work\n",
      "contextlib2==21.6.0\n",
      "contourpy @ file:///opt/conda/conda-bld/contourpy_1663827406301/work\n",
      "cryptography @ file:///home/conda/feedstock_root/build_artifacts/cryptography-split_1685659424938/work\n",
      "cycler @ file:///home/conda/feedstock_root/build_artifacts/cycler_1635519461629/work\n",
      "Cython @ file:///home/conda/feedstock_root/build_artifacts/cython_1685025003072/work\n",
      "dask==2024.1.1\n",
      "dataclasses-json==0.6.4\n",
      "datasets==2.14.6\n",
      "debugpy @ file:///croot/debugpy_1690905042057/work\n",
      "decorator @ file:///opt/conda/conda-bld/decorator_1643638310831/work\n",
      "Deprecated==1.2.14\n",
      "dill==0.3.7\n",
      "dpcpp-llvm-spirv==0.0.0\n",
      "dpctl==0.14.4+27.ga3cde67f7\n",
      "dpnp==0.12.0\n",
      "earthengine-api==0.1.386\n",
      "eerepr==0.0.4\n",
      "einops==0.7.0\n",
      "evaluate==0.4.1\n",
      "exceptiongroup @ file:///croot/exceptiongroup_1668714342571/work\n",
      "executing @ file:///opt/conda/conda-bld/executing_1646925071911/work\n",
      "fastapi==0.109.0\n",
      "filelock==3.13.1\n",
      "flatbuffers==23.5.26\n",
      "folium==0.15.1\n",
      "fonttools==4.25.0\n",
      "frozenlist==1.4.1\n",
      "fsspec==2023.10.0\n",
      "funcsigs==1.0.2\n",
      "future @ file:///home/conda/feedstock_root/build_artifacts/future_1673596611778/work\n",
      "geemap==0.30.4\n",
      "geocoder==1.38.1\n",
      "google-api-core==2.16.1\n",
      "google-api-python-client==2.116.0\n",
      "google-auth==2.27.0\n",
      "google-auth-httplib2==0.2.0\n",
      "google-cloud-core==2.4.1\n",
      "google-cloud-storage==2.14.0\n",
      "google-crc32c==1.5.0\n",
      "google-resumable-media==2.7.0\n",
      "googleapis-common-protos==1.62.0\n",
      "gpt4all==1.0.12\n",
      "grapheme==0.6.0\n",
      "greenlet==3.0.3\n",
      "grpcio==1.60.1\n",
      "h11==0.14.0\n",
      "httplib2==0.22.0\n",
      "httptools==0.6.1\n",
      "huggingface-hub==0.17.3\n",
      "humanfriendly==10.0\n",
      "idna @ file:///home/conda/feedstock_root/build_artifacts/idna_1663625384323/work\n",
      "importlib-metadata @ file:///croot/importlib-metadata_1678997070253/work\n",
      "importlib-resources==6.1.1\n",
      "intel-extension-for-pytorch==2.1.100\n",
      "intel-extension-for-transformers==1.2.2\n",
      "ipyevents==2.0.2\n",
      "ipyfilechooser==0.6.0\n",
      "ipykernel @ file:///croot/ipykernel_1691121631942/work\n",
      "ipyleaflet==0.18.2\n",
      "ipython @ file:///croot/ipython_1694181358621/work\n",
      "ipytree==0.2.2\n",
      "ipywidgets @ file:///croot/ipywidgets_1679394798311/work\n",
      "jedi @ file:///tmp/build/80754af9/jedi_1644297102865/work\n",
      "Jinja2==3.1.3\n",
      "joblib @ file:///home/conda/feedstock_root/build_artifacts/joblib_1663332044897/work\n",
      "jsonpatch==1.33\n",
      "jsonpointer==2.0\n",
      "jsonschema==4.21.1\n",
      "jsonschema-specifications==2023.12.1\n",
      "jstyleson==0.0.2\n",
      "jupyter_client @ file:///croot/jupyter_client_1680171862562/work\n",
      "jupyter_core @ file:///croot/jupyter_core_1679906564508/work\n",
      "jupyterlab-widgets @ file:///croot/jupyterlab_widgets_1679055282532/work\n",
      "kiwisolver @ file:///home/conda/feedstock_root/build_artifacts/kiwisolver_1666805784128/work\n",
      "kubernetes==29.0.0\n",
      "langchain==0.0.335\n",
      "langsmith==0.0.85\n",
      "libarchive-c @ file:///home/conda/feedstock_root/build_artifacts/python-libarchive-c_1666852475034/work\n",
      "llvmlite==0.40.0\n",
      "locket==1.0.0\n",
      "markdown-it-py==3.0.0\n",
      "MarkupSafe==2.1.4\n",
      "marshmallow==3.20.2\n",
      "matplotlib @ file:///croot/matplotlib-suite_1670466153205/work\n",
      "matplotlib-inline @ file:///opt/conda/conda-bld/matplotlib-inline_1662014470464/work\n",
      "mdurl==0.1.2\n",
      "mkl-fft==1.3.6\n",
      "mkl-random==1.2.2\n",
      "mkl-service==2.4.0\n",
      "mkl-umath==0.1.1\n",
      "monotonic==1.6\n",
      "mpmath==1.3.0\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.15\n",
      "munkres==1.1.4\n",
      "mypy-extensions==1.0.0\n",
      "natsort==8.4.0\n",
      "nest-asyncio @ file:///croot/nest-asyncio_1672387112409/work\n",
      "networkx==3.1\n",
      "neural-compressor==2.4.1\n",
      "neural-speed==0.2\n",
      "ninja==1.10.2.4\n",
      "nltk==3.8.1\n",
      "nncf==2.8.0\n",
      "node==1.2.1\n",
      "npm==0.1.1\n",
      "numba @ file:///home/conda/feedstock_root/build_artifacts/numba_1686793463639/work\n",
      "numba-dpex==0.21.0\n",
      "numexpr @ file:///croot/numexpr_1696515281613/work\n",
      "numpy==1.24.3\n",
      "nvidia-cublas-cu12==12.1.3.1\n",
      "nvidia-cuda-cupti-cu12==12.1.105\n",
      "nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "nvidia-cuda-runtime-cu12==12.1.105\n",
      "nvidia-cudnn-cu12==8.9.2.26\n",
      "nvidia-cufft-cu12==11.0.2.54\n",
      "nvidia-curand-cu12==10.3.2.106\n",
      "nvidia-cusolver-cu12==11.4.5.107\n",
      "nvidia-cusparse-cu12==12.1.0.106\n",
      "nvidia-nccl-cu12==2.18.1\n",
      "nvidia-nvjitlink-cu12==12.3.101\n",
      "nvidia-nvtx-cu12==12.1.105\n",
      "oauthlib==3.2.2\n",
      "odict==1.9.0\n",
      "onnx==1.15.0\n",
      "onnxruntime==1.14.1\n",
      "opencv-python-headless==4.9.0.80\n",
      "opentelemetry-api==1.22.0\n",
      "opentelemetry-exporter-otlp-proto-common==1.22.0\n",
      "opentelemetry-exporter-otlp-proto-grpc==1.22.0\n",
      "opentelemetry-proto==1.22.0\n",
      "opentelemetry-sdk==1.22.0\n",
      "opentelemetry-semantic-conventions==0.43b0\n",
      "openvino==2023.3.0\n",
      "openvino-telemetry==2023.2.1\n",
      "optimum==1.16.2\n",
      "optimum-intel==1.14.0\n",
      "optional-django==0.1.0\n",
      "overrides==7.7.0\n",
      "packaging @ file:///home/conda/feedstock_root/build_artifacts/packaging_1681337016113/work\n",
      "pandas @ file:///croot/pandas_1692289311655/work\n",
      "parso @ file:///opt/conda/conda-bld/parso_1641458642106/work\n",
      "partd==1.4.1\n",
      "pexpect @ file:///tmp/build/80754af9/pexpect_1605563209008/work\n",
      "pickleshare @ file:///tmp/build/80754af9/pickleshare_1606932040724/work\n",
      "Pillow @ file:///home/conda/feedstock_root/build_artifacts/pillow_1688255839723/work\n",
      "platformdirs @ file:///home/conda/feedstock_root/build_artifacts/platformdirs_1687097136512/work\n",
      "plotly==5.18.0\n",
      "pluggy @ file:///home/conda/feedstock_root/build_artifacts/pluggy_1667232663820/work\n",
      "plumber==1.7\n",
      "pooch @ file:///home/conda/feedstock_root/build_artifacts/pooch_1679580333621/work\n",
      "posthog==3.3.4\n",
      "prettytable==3.9.0\n",
      "prompt-toolkit @ file:///croot/prompt-toolkit_1672387306916/work\n",
      "protobuf==4.25.2\n",
      "psutil @ file:///opt/conda/conda-bld/psutil_1656431268089/work\n",
      "ptyprocess @ file:///tmp/build/80754af9/ptyprocess_1609355006118/work/dist/ptyprocess-0.7.0-py2.py3-none-any.whl\n",
      "pulsar-client==3.4.0\n",
      "pure-eval @ file:///opt/conda/conda-bld/pure_eval_1646925070566/work\n",
      "py-cpuinfo==9.0.0\n",
      "pyarrow==15.0.0\n",
      "pyarrow-hotfix==0.6\n",
      "pyasn1==0.5.1\n",
      "pyasn1-modules==0.3.0\n",
      "pycocotools==2.0.7\n",
      "pycosat @ file:///home/conda/feedstock_root/build_artifacts/pycosat_1666836642684/work\n",
      "pycparser @ file:///home/conda/feedstock_root/build_artifacts/pycparser_1636257122734/work\n",
      "pydantic==2.6.0\n",
      "pydantic_core==2.16.1\n",
      "pydot==2.0.0\n",
      "pyeditline==2.0.1\n",
      "Pygments @ file:///croot/pygments_1684279966437/work\n",
      "pygpt4all==1.1.0\n",
      "pygptj==2.0.3\n",
      "pyllamacpp==2.4.2\n",
      "pymoo==0.6.1.1\n",
      "pyOpenSSL @ file:///home/conda/feedstock_root/build_artifacts/pyopenssl_1685514481738/work\n",
      "pyparsing @ file:///home/conda/feedstock_root/build_artifacts/pyparsing_1687132014935/work\n",
      "pyperclip==1.8.2\n",
      "PyPika==0.48.9\n",
      "pyshp==2.3.1\n",
      "PySocks @ file:///home/conda/feedstock_root/build_artifacts/pysocks_1648857263093/work\n",
      "python-box==7.1.1\n",
      "python-dateutil @ file:///home/conda/feedstock_root/build_artifacts/python-dateutil_1626286286081/work\n",
      "python-dotenv==1.0.1\n",
      "pytz @ file:///home/conda/feedstock_root/build_artifacts/pytz_1680088766131/work\n",
      "PyYAML @ file:///home/conda/feedstock_root/build_artifacts/pyyaml_1666772387118/work\n",
      "pyzmq @ file:///croot/pyzmq_1686601365461/work\n",
      "ratelim==0.1.6\n",
      "referencing==0.33.0\n",
      "regex==2023.12.25\n",
      "requests @ file:///home/conda/feedstock_root/build_artifacts/requests_1684774241324/work\n",
      "requests-oauthlib==1.3.1\n",
      "responses==0.18.0\n",
      "rich==13.7.0\n",
      "rpds-py==0.17.1\n",
      "rsa==4.9\n",
      "ruamel.yaml @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml_1686993888032/work\n",
      "ruamel.yaml.clib @ file:///home/conda/feedstock_root/build_artifacts/ruamel.yaml.clib_1670412733608/work\n",
      "safetensors==0.4.2\n",
      "schema==0.7.5\n",
      "scikit-learn @ file:///home/conda/feedstock_root/build_artifacts/scikit-learn_1685023709438/work\n",
      "scipy==1.10.1\n",
      "scooby==0.9.2\n",
      "seaborn @ file:///croot/seaborn_1673479180098/work\n",
      "sentence-transformers==2.2.2\n",
      "sentencepiece==0.1.99\n",
      "six @ file:///home/conda/feedstock_root/build_artifacts/six_1620240208055/work\n",
      "SMP==0.1.4\n",
      "sniffio==1.3.0\n",
      "SQLAlchemy==2.0.25\n",
      "stack-data @ file:///opt/conda/conda-bld/stack_data_1646927590127/work\n",
      "starlette==0.35.1\n",
      "sympy==1.12\n",
      "TBB==0.2\n",
      "tenacity==8.2.3\n",
      "texttable==1.7.0\n",
      "threadpoolctl @ file:///home/conda/feedstock_root/build_artifacts/threadpoolctl_1643647933166/work\n",
      "tiktoken==0.4.0\n",
      "tokenizers==0.14.1\n",
      "toolz @ file:///home/conda/feedstock_root/build_artifacts/toolz_1657485559105/work\n",
      "torch==2.1.1\n",
      "torchvision==0.17.0\n",
      "tornado @ file:///croot/tornado_1690848263220/work\n",
      "tqdm @ file:///home/conda/feedstock_root/build_artifacts/tqdm_1677948868469/work\n",
      "traitlets @ file:///croot/traitlets_1671143879854/work\n",
      "traittypes==0.2.1\n",
      "transformers==4.34.1\n",
      "triton==2.1.0\n",
      "typer==0.9.0\n",
      "typing-inspect==0.9.0\n",
      "typing_extensions==4.9.0\n",
      "tzdata @ file:///croot/python-tzdata_1690578112552/work\n",
      "uritemplate==4.1.1\n",
      "urllib3 @ file:///home/conda/feedstock_root/build_artifacts/urllib3_1686156552494/work\n",
      "uvicorn==0.27.0.post1\n",
      "uvloop==0.19.0\n",
      "watchfiles==0.21.0\n",
      "wcwidth @ file:///Users/ktietz/demo/mc3/conda-bld/wcwidth_1629357192024/work\n",
      "websocket-client==1.7.0\n",
      "websockets==12.0\n",
      "widgetsnbextension @ file:///croot/widgetsnbextension_1679313860248/work\n",
      "wrapt==1.16.0\n",
      "xgboost==1.7.3\n",
      "xxhash==3.4.1\n",
      "xyzservices==2023.10.1\n",
      "yarl==1.9.4\n",
      "zipp @ file:///croot/zipp_1672387121353/work\n",
      "zope.component==6.0\n",
      "zope.deferredimport==5.0\n",
      "zope.deprecation==5.0\n",
      "zope.event==5.0\n",
      "zope.hookable==6.0\n",
      "zope.interface==6.1\n",
      "zope.lifecycleevent==5.0\n",
      "zope.proxy==5.1\n",
      "zstandard==0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcc5166-eac5-45f6-8f15-56b628c053ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ":: WARNING: setvars.sh has already been run. Skipping re-execution.\n",
      "   To force a re-execution of setvars.sh, use the '--force' option.\n",
      "   Using '--force' can result in excessive use of your environment variables.\n",
      "  \n",
      "usage: source setvars.sh [--force] [--config=file] [--help] [...]\n",
      "  --force        Force setvars.sh to re-run, doing so may overload environment.\n",
      "  --config=file  Customize env vars using a setvars.sh configuration file.\n",
      "  --help         Display this help message and exit.\n",
      "  ...            Additional args are passed to individual env/vars.sh scripts\n",
      "                 and should follow this script's arguments.\n",
      "  \n",
      "  Some POSIX shells do not accept command-line options. In that case, you can pass\n",
      "  command-line options via the SETVARS_ARGS environment variable. For example:\n",
      "  \n",
      "  $ SETVARS_ARGS=\"ia32 --config=config.txt\" ; export SETVARS_ARGS\n",
      "  $ . path/to/setvars.sh\n",
      "  \n",
      "  The SETVARS_ARGS environment variable is cleared on exiting setvars.sh.\n",
      "  \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: optimum==1.16.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (1.16.2)\n",
      "Requirement already satisfied: coloredlogs in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum==1.16.2) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum==1.16.2) (1.12)\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum==1.16.2) (4.34.1)\n",
      "Requirement already satisfied: torch>=1.11 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum==1.16.2) (2.1.1)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from optimum==1.16.2) (23.1)\n",
      "Requirement already satisfied: numpy in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from optimum==1.16.2) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum==1.16.2) (0.17.3)\n",
      "Requirement already satisfied: datasets in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum==1.16.2) (2.14.6)\n",
      "Requirement already satisfied: filelock in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.16.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.16.2) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.16.2) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.16.2) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.16.2) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum==1.16.2) (4.9.0)\n",
      "Requirement already satisfied: networkx in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.11->optimum==1.16.2) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11->optimum==1.16.2) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.16.2) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.16.2) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.16.2) (0.4.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.16.2) (0.1.99)\n",
      "Requirement already satisfied: protobuf in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.16.2) (4.25.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from coloredlogs->optimum==1.16.2) (10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum==1.16.2) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum==1.16.2) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->optimum==1.16.2) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum==1.16.2) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum==1.16.2) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum==1.16.2) (3.9.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from sympy->optimum==1.16.2) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum==1.16.2) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum==1.16.2) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum==1.16.2) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum==1.16.2) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum==1.16.2) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum==1.16.2) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.16.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.16.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.16.2) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.16.2) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from jinja2->torch>=1.11->optimum==1.16.2) (2.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->optimum==1.16.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->optimum==1.16.2) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->optimum==1.16.2) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.16.2) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting optimum[neural-compressor]==1.14.0\n",
      "  Downloading optimum-1.14.0-py3-none-any.whl (398 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.9/398.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: coloredlogs in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (15.0.1)\n",
      "Requirement already satisfied: sympy in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (1.12)\n",
      "Requirement already satisfied: transformers[sentencepiece]>=4.26.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (4.34.1)\n",
      "Requirement already satisfied: torch>=1.9 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (2.1.1)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (23.1)\n",
      "Requirement already satisfied: numpy in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (0.17.3)\n",
      "Requirement already satisfied: datasets in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (2.14.6)\n",
      "Requirement already satisfied: optimum-intel[neural-compressor]>=1.11.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum[neural-compressor]==1.14.0) (1.14.0)\n",
      "Requirement already satisfied: filelock in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (3.13.1)\n",
      "Requirement already satisfied: fsspec in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (4.9.0)\n",
      "Requirement already satisfied: sentencepiece in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (0.1.99)\n",
      "Requirement already satisfied: scipy in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.10.1)\n",
      "Requirement already satisfied: accelerate in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (0.26.1)\n",
      "Requirement already satisfied: neural-compressor>=2.2.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (2.4.1)\n",
      "Requirement already satisfied: onnx in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.15.0)\n",
      "Requirement already satisfied: onnxruntime<1.15.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.14.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum[neural-compressor]==1.14.0) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum[neural-compressor]==1.14.0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->optimum[neural-compressor]==1.14.0) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum[neural-compressor]==1.14.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum[neural-compressor]==1.14.0) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets->optimum[neural-compressor]==1.14.0) (3.9.3)\n",
      "Requirement already satisfied: networkx in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch>=1.9->optimum[neural-compressor]==1.14.0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->optimum[neural-compressor]==1.14.0) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]==1.14.0) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]==1.14.0) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]==1.14.0) (0.4.2)\n",
      "Requirement already satisfied: protobuf in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers[sentencepiece]>=4.26.0->optimum[neural-compressor]==1.14.0) (4.25.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from coloredlogs->optimum[neural-compressor]==1.14.0) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from sympy->optimum[neural-compressor]==1.14.0) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum[neural-compressor]==1.14.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum[neural-compressor]==1.14.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum[neural-compressor]==1.14.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum[neural-compressor]==1.14.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum[neural-compressor]==1.14.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets->optimum[neural-compressor]==1.14.0) (4.0.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.2.14)\n",
      "Requirement already satisfied: opencv-python-headless in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (4.9.0.80)\n",
      "Requirement already satisfied: Pillow in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (10.0.0)\n",
      "Requirement already satisfied: prettytable in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (3.9.0)\n",
      "Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (9.0.0)\n",
      "Requirement already satisfied: schema in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (0.7.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.2.2)\n",
      "Requirement already satisfied: pycocotools in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (2.0.7)\n",
      "Requirement already satisfied: flatbuffers in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from onnxruntime<1.15.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (23.5.26)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface-hub>=0.8.0->optimum[neural-compressor]==1.14.0) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from jinja2->torch>=1.9->optimum[neural-compressor]==1.14.0) (2.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->optimum[neural-compressor]==1.14.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->optimum[neural-compressor]==1.14.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->optimum[neural-compressor]==1.14.0) (2023.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from deprecated>=1.2.13->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum[neural-compressor]==1.14.0) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from prettytable->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (0.2.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (3.6.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from schema->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (21.6.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from scikit-learn->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from scikit-learn->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor>=2.2.0->optimum-intel[neural-compressor]>=1.11.0->optimum[neural-compressor]==1.14.0) (3.1.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: optimum\n",
      "  Attempting uninstall: optimum\n",
      "    Found existing installation: optimum 1.16.2\n",
      "    Uninstalling optimum-1.16.2:\n",
      "      Successfully uninstalled optimum-1.16.2\n",
      "\u001b[33m  WARNING: The script optimum-cli is installed in '/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed optimum-1.14.0\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: evaluate==0.4.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from evaluate==0.4.1) (2.14.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from evaluate==0.4.1) (1.24.3)\n",
      "Requirement already satisfied: dill in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from evaluate==0.4.1) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from evaluate==0.4.1) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from evaluate==0.4.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from evaluate==0.4.1) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from evaluate==0.4.1) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from evaluate==0.4.1) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from evaluate==0.4.1) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from evaluate==0.4.1) (0.17.3)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from evaluate==0.4.1) (23.1)\n",
      "Requirement already satisfied: responses<0.19 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from evaluate==0.4.1) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (15.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets>=2.0.0->evaluate==0.4.1) (6.0)\n",
      "Requirement already satisfied: filelock in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->evaluate==0.4.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->evaluate==0.4.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->evaluate==0.4.1) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->evaluate==0.4.1) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->evaluate==0.4.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->evaluate==0.4.1) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->evaluate==0.4.1) (2023.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (4.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->evaluate==0.4.1) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting datasets==2.16.0\n",
      "  Using cached datasets-2.16.0-py3-none-any.whl (507 kB)\n",
      "Requirement already satisfied: filelock in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets==2.16.0) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets==2.16.0) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets==2.16.0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets==2.16.0) (4.65.0)\n",
      "Requirement already satisfied: xxhash in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from datasets==2.16.0) (3.9.3)\n",
      "Collecting huggingface-hub>=0.19.4 (from datasets==2.16.0)\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets==2.16.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets==2.16.0) (6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.16.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.16.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.16.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.16.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.16.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from aiohttp->datasets==2.16.0) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub>=0.19.4->datasets==2.16.0) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.16.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.16.0) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->datasets==2.16.0) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets==2.16.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets==2.16.0) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets==2.16.0) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.16.0) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: huggingface-hub, datasets\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.6\n",
      "    Uninstalling datasets-2.14.6:\n",
      "      Successfully uninstalled datasets-2.14.6\n",
      "\u001b[33m  WARNING: The script datasets-cli is installed in '/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.16.0 huggingface-hub-0.20.3\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!source /opt/intel/oneapi/setvars.sh #comment out if not running on Intel Developer Cloud Jupyter\n",
    "!python -m pip install optimum==1.16.2\n",
    "!pip install --upgrade-strategy eager optimum[neural-compressor]==1.14.0\n",
    "!pip install evaluate==0.4.1\n",
    "!pip install datasets==2.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d489b48-dc19-4cf3-ad4b-ae2b94177cbf",
   "metadata": {},
   "source": [
    "#### Importing Libraries and Setting Up Quantization Environment\n",
    "\n",
    "This cell is the starting point of our journey into model quantization. Here, we import a set of libraries and modules that are essential for both setting up our model and preparing it for the quantization process.\n",
    "\n",
    "- `import evaluate`: This import brings in the `evaluate` library, which is crucial for assessing the performance of our model. It provides a straightforward way to evaluate various metrics, which is vital for understanding the impact of quantization on model accuracy.\n",
    "\n",
    "- `from optimum.intel import INCQuantizer`: The `INCQuantizer` from the Optimum Intel library is a key component for this workshop. It is specifically designed to handle the quantization process, allowing us to convert our model into a more efficient format suitable for faster inference.\n",
    "\n",
    "- `from datasets import load_dataset`: We use the `datasets` library to load the dataset required for evaluating our model. This step is essential for ensuring that we have the right data to fine-tune and assess our model's performance.\n",
    "\n",
    "- `from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline`: These imports from the Hugging Face Transformers library are critical for loading our pre-trained model and tokenizer. `AutoModelForQuestionAnswering` and `AutoTokenizer` will be used to set up our model for the question-answering task. The `pipeline` function allows us to create a seamless flow for data processing and inference.\n",
    "\n",
    "- `from neural_compressor.config import AccuracyCriterion, TuningCriterion, PostTrainingQuantConfig`: These imports from the Neural Compressor library are used to configure the quantization process. `AccuracyCriterion` and `TuningCriterion` allow us to set parameters that define the acceptable accuracy loss and the tuning process for quantization. `PostTrainingQuantConfig` provides the necessary configuration for post-training quantization, which is the approach we will be using.\n",
    "\n",
    "Each of these imports plays a vital role in preparing our environment for quantizing a model effectively, setting the stage for the subsequent steps in this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf7e97d-c3ca-4849-aae1-c95bbfc1875e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from optimum.intel import INCQuantizer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "from neural_compressor.config import AccuracyCriterion, TuningCriterion, PostTrainingQuantConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f08be3-299a-4d3e-8aa1-3479665c0bc3",
   "metadata": {},
   "source": [
    "#### Model and Dataset Preparation\n",
    "\n",
    "We initialize our DistilBERT model and tokenizer specifically tuned for the SQuAD dataset. A subset of the validation set from SQuAD is loaded for evaluation purposes. The `evaluate` library is used to set up an evaluator for the question-answering task, and a pipeline is created for processing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f86e08fb-ab78-4522-a40a-14da03ad3d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "eval_dataset = load_dataset(\"squad\", split=\"validation\").select(range(64))\n",
    "task_evaluator = evaluate.evaluator(\"question-answering\")\n",
    "qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5024c3d6-5b3a-4b03-88c2-0626c9c3082f",
   "metadata": {},
   "source": [
    "#### Evaluation Function Definition\n",
    "\n",
    "Here, we define `eval_fn`, a function that will be used to evaluate the quantized model's performance. This function integrates our model with the question-answering pipeline and returns the F1 score, a measure of the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af50d4d2-2b6b-40ef-b100-cb65c0a0deaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(model):\n",
    "    qa_pipeline.model = model\n",
    "    metrics = task_evaluator.compute(model_or_pipeline=qa_pipeline, data=eval_dataset, metric=\"squad\")\n",
    "    return metrics[\"f1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f05e4a9-3617-4776-a60d-a8968e891dec",
   "metadata": {},
   "source": [
    "#### Quantization Configuration\n",
    "\n",
    "In this cell, we set up the configuration for dynamic quantization. We specify our tolerable accuracy loss (5%) and the maximum number of tuning trials (10). The `PostTrainingQuantConfig` is set to a dynamic approach, aligning with our focus on dynamic quantization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e4a5d36-26b2-4986-818e-750a1f5795c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the accepted accuracy loss to 5%\n",
    "accuracy_criterion = AccuracyCriterion(tolerable_loss=0.05)\n",
    "# Set the maximum number of trials to 10\n",
    "tuning_criterion = TuningCriterion(max_trials=10)\n",
    "quantization_config = PostTrainingQuantConfig(\n",
    "    approach=\"dynamic\", accuracy_criterion=accuracy_criterion, tuning_criterion=tuning_criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e4a11-0d00-4440-9748-6bad6fc47e8a",
   "metadata": {},
   "source": [
    "#### Model Quantization and Saving\n",
    "\n",
    "We initialize the quantizer with our model and the evaluation function. The model is then quantized according to our defined configuration. The quantized model is saved in the specified directory, enabling us to use or deploy it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7717499d-7eed-4753-8044-2874ff6a9ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 08:08:09 [INFO] Start auto tuning.\n",
      "2024-02-02 08:08:09 [INFO] Execute the tuning process due to detect the evaluation function.\n",
      "2024-02-02 08:08:09 [INFO] Adaptor has 5 recipes.\n",
      "2024-02-02 08:08:09 [INFO] 0 recipes specified by user.\n",
      "2024-02-02 08:08:09 [INFO] 3 recipes require future tuning.\n",
      "2024-02-02 08:08:09 [INFO] *** Initialize auto tuning\n",
      "2024-02-02 08:08:09 [INFO] {\n",
      "2024-02-02 08:08:09 [INFO]     'PostTrainingQuantConfig': {\n",
      "2024-02-02 08:08:09 [INFO]         'AccuracyCriterion': {\n",
      "2024-02-02 08:08:09 [INFO]             'criterion': 'relative',\n",
      "2024-02-02 08:08:09 [INFO]             'higher_is_better': True,\n",
      "2024-02-02 08:08:09 [INFO]             'tolerable_loss': 0.05,\n",
      "2024-02-02 08:08:09 [INFO]             'absolute': None,\n",
      "2024-02-02 08:08:09 [INFO]             'keys': <bound method AccuracyCriterion.keys of <neural_compressor.config.AccuracyCriterion object at 0x153887596670>>,\n",
      "2024-02-02 08:08:09 [INFO]             'relative': 0.05\n",
      "2024-02-02 08:08:09 [INFO]         },\n",
      "2024-02-02 08:08:09 [INFO]         'approach': 'post_training_dynamic_quant',\n",
      "2024-02-02 08:08:09 [INFO]         'backend': 'default',\n",
      "2024-02-02 08:08:09 [INFO]         'calibration_sampling_size': [\n",
      "2024-02-02 08:08:09 [INFO]             100\n",
      "2024-02-02 08:08:09 [INFO]         ],\n",
      "2024-02-02 08:08:09 [INFO]         'device': 'cpu',\n",
      "2024-02-02 08:08:09 [INFO]         'diagnosis': False,\n",
      "2024-02-02 08:08:09 [INFO]         'domain': 'auto',\n",
      "2024-02-02 08:08:09 [INFO]         'example_inputs': 'Not printed here due to large size tensors...',\n",
      "2024-02-02 08:08:09 [INFO]         'excluded_precisions': [\n",
      "2024-02-02 08:08:09 [INFO]         ],\n",
      "2024-02-02 08:08:09 [INFO]         'framework': 'pytorch_fx',\n",
      "2024-02-02 08:08:09 [INFO]         'inputs': [\n",
      "2024-02-02 08:08:09 [INFO]         ],\n",
      "2024-02-02 08:08:09 [INFO]         'model_name': '',\n",
      "2024-02-02 08:08:09 [INFO]         'ni_workload_name': 'quantization',\n",
      "2024-02-02 08:08:09 [INFO]         'op_name_dict': None,\n",
      "2024-02-02 08:08:09 [INFO]         'op_type_dict': None,\n",
      "2024-02-02 08:08:09 [INFO]         'outputs': [\n",
      "2024-02-02 08:08:09 [INFO]         ],\n",
      "2024-02-02 08:08:09 [INFO]         'quant_format': 'default',\n",
      "2024-02-02 08:08:09 [INFO]         'quant_level': 'auto',\n",
      "2024-02-02 08:08:09 [INFO]         'recipes': {\n",
      "2024-02-02 08:08:09 [INFO]             'smooth_quant': False,\n",
      "2024-02-02 08:08:09 [INFO]             'smooth_quant_args': {\n",
      "2024-02-02 08:08:09 [INFO]             },\n",
      "2024-02-02 08:08:09 [INFO]             'layer_wise_quant': False,\n",
      "2024-02-02 08:08:09 [INFO]             'layer_wise_quant_args': {\n",
      "2024-02-02 08:08:09 [INFO]             },\n",
      "2024-02-02 08:08:09 [INFO]             'fast_bias_correction': False,\n",
      "2024-02-02 08:08:09 [INFO]             'weight_correction': False,\n",
      "2024-02-02 08:08:09 [INFO]             'gemm_to_matmul': True,\n",
      "2024-02-02 08:08:09 [INFO]             'graph_optimization_level': None,\n",
      "2024-02-02 08:08:09 [INFO]             'first_conv_or_matmul_quantization': True,\n",
      "2024-02-02 08:08:09 [INFO]             'last_conv_or_matmul_quantization': True,\n",
      "2024-02-02 08:08:09 [INFO]             'pre_post_process_quantization': True,\n",
      "2024-02-02 08:08:09 [INFO]             'add_qdq_pair_to_weight': False,\n",
      "2024-02-02 08:08:09 [INFO]             'optypes_to_exclude_output_quant': [\n",
      "2024-02-02 08:08:09 [INFO]             ],\n",
      "2024-02-02 08:08:09 [INFO]             'dedicated_qdq_pair': False,\n",
      "2024-02-02 08:08:09 [INFO]             'rtn_args': {\n",
      "2024-02-02 08:08:09 [INFO]             },\n",
      "2024-02-02 08:08:09 [INFO]             'awq_args': {\n",
      "2024-02-02 08:08:09 [INFO]             },\n",
      "2024-02-02 08:08:09 [INFO]             'gptq_args': {\n",
      "2024-02-02 08:08:09 [INFO]             },\n",
      "2024-02-02 08:08:09 [INFO]             'teq_args': {\n",
      "2024-02-02 08:08:09 [INFO]             }\n",
      "2024-02-02 08:08:09 [INFO]         },\n",
      "2024-02-02 08:08:09 [INFO]         'reduce_range': None,\n",
      "2024-02-02 08:08:09 [INFO]         'TuningCriterion': {\n",
      "2024-02-02 08:08:09 [INFO]             'max_trials': 10,\n",
      "2024-02-02 08:08:09 [INFO]             'objective': [\n",
      "2024-02-02 08:08:09 [INFO]                 'performance'\n",
      "2024-02-02 08:08:09 [INFO]             ],\n",
      "2024-02-02 08:08:09 [INFO]             'strategy': 'basic',\n",
      "2024-02-02 08:08:09 [INFO]             'strategy_kwargs': None,\n",
      "2024-02-02 08:08:09 [INFO]             'timeout': 0\n",
      "2024-02-02 08:08:09 [INFO]         },\n",
      "2024-02-02 08:08:09 [INFO]         'use_bf16': True\n",
      "2024-02-02 08:08:09 [INFO]     }\n",
      "2024-02-02 08:08:09 [INFO] }\n",
      "2024-02-02 08:08:09 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n",
      "2024-02-02 08:08:10 [INFO]  Found 6 blocks\n",
      "2024-02-02 08:08:10 [INFO] Attention Blocks: 6\n",
      "2024-02-02 08:08:10 [INFO] FFN Blocks: 6\n",
      "2024-02-02 08:08:10 [INFO] Pass query framework capability elapsed time: 334.35 ms\n",
      "2024-02-02 08:08:10 [INFO] Get FP32 model baseline.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fc50489b9eb4a4f8c3d22cc15a9c578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`squad_v2_format` parameter not provided to QuestionAnsweringEvaluator.compute(). Automatically inferred `squad_v2_format` as False.\n",
      "2024-02-02 08:08:12 [INFO] Save tuning history to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/./history.snapshot.\n",
      "2024-02-02 08:08:12 [INFO] FP32 baseline is: [Accuracy: 88.1250, Duration (seconds): 1.8365]\n",
      "2024-02-02 08:08:12 [INFO] Quantize the model with default config.\n",
      "2024-02-02 08:08:12 [INFO] Fx trace of the entire model failed, We will conduct auto quantization\n",
      "2024-02-02 08:08:14 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-02-02 08:08:14 [INFO] +-----------------+----------+---------+\n",
      "2024-02-02 08:08:14 [INFO] |     Op Type     |  Total   |   INT8  |\n",
      "2024-02-02 08:08:14 [INFO] +-----------------+----------+---------+\n",
      "2024-02-02 08:08:14 [INFO] |    Embedding    |    2     |    2    |\n",
      "2024-02-02 08:08:14 [INFO] |      Linear     |    37    |    37   |\n",
      "2024-02-02 08:08:14 [INFO] +-----------------+----------+---------+\n",
      "2024-02-02 08:08:14 [INFO] Pass quantize model elapsed time: 1899.54 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b3648c7c90491c95802e99f5d8d14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`squad_v2_format` parameter not provided to QuestionAnsweringEvaluator.compute(). Automatically inferred `squad_v2_format` as False.\n",
      "2024-02-02 08:08:15 [INFO] Tune 1 result is: [Accuracy (int8|fp32): 82.0486|88.1250, Duration (seconds) (int8|fp32): 1.5482|1.8365], Best tune result is: n/a\n",
      "2024-02-02 08:08:15 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2024-02-02 08:08:15 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:15 [INFO] |     Info Type      | Baseline | Tune 1 result | Best tune result |\n",
      "2024-02-02 08:08:15 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:15 [INFO] |      Accuracy      | 88.1250  |    82.0486    |       n/a        |\n",
      "2024-02-02 08:08:15 [INFO] | Duration (seconds) | 1.8365   |    1.5482     |       n/a        |\n",
      "2024-02-02 08:08:15 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:15 [INFO] Save tuning history to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/./history.snapshot.\n",
      "2024-02-02 08:08:15 [INFO] *** Start conservative tuning.\n",
      "2024-02-02 08:08:15 [INFO] Execute the tuning process due to detect the evaluation function.\n",
      "2024-02-02 08:08:15 [INFO] Adaptor has 5 recipes.\n",
      "2024-02-02 08:08:15 [INFO] 0 recipes specified by user.\n",
      "2024-02-02 08:08:15 [INFO] 3 recipes require future tuning.\n",
      "2024-02-02 08:08:15 [INFO] *** Initialize conservative tuning\n",
      "2024-02-02 08:08:15 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2024-02-02 08:08:15 [INFO] FP32 baseline is: [Accuracy: 88.1250, Duration (seconds): 1.8365]\n",
      "2024-02-02 08:08:15 [INFO] *** Try to convert op into lower precision to improve performance.\n",
      "2024-02-02 08:08:15 [INFO] *** Start to convert op into int8.\n",
      "2024-02-02 08:08:15 [INFO] *** Try to convert all linear ops into int8.\n",
      "2024-02-02 08:08:15 [INFO] Fx trace of the entire model failed, We will conduct auto quantization\n",
      "2024-02-02 08:08:17 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-02-02 08:08:17 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:17 [INFO] |   Op Type   | Total  | INT8 |  FP32  |\n",
      "2024-02-02 08:08:17 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:17 [INFO] |    Linear   |   37   |  37  |   0    |\n",
      "2024-02-02 08:08:17 [INFO] |  Embedding  |   2    |  0   |   2    |\n",
      "2024-02-02 08:08:17 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:17 [INFO] Pass quantize model elapsed time: 1424.77 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae22d90500dc4490b5495e1a97621753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`squad_v2_format` parameter not provided to QuestionAnsweringEvaluator.compute(). Automatically inferred `squad_v2_format` as False.\n",
      "2024-02-02 08:08:18 [INFO] Tune 2 result is: [Accuracy (int8|fp32): 83.0208|88.1250, Duration (seconds) (int8|fp32): 1.5677|1.8365], Best tune result is: n/a\n",
      "2024-02-02 08:08:18 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2024-02-02 08:08:18 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:18 [INFO] |     Info Type      | Baseline | Tune 2 result | Best tune result |\n",
      "2024-02-02 08:08:18 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:18 [INFO] |      Accuracy      | 88.1250  |    83.0208    |       n/a        |\n",
      "2024-02-02 08:08:18 [INFO] | Duration (seconds) | 1.8365   |    1.5677     |       n/a        |\n",
      "2024-02-02 08:08:18 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:18 [INFO] Save tuning history to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/./history.snapshot.\n",
      "2024-02-02 08:08:18 [INFO] *** Convert all linear ops to int8 but accuracy not meet the requirements\n",
      "2024-02-02 08:08:18 [INFO] ***Current result dict_items([('conv', None), ('matmul', None), ('bmm', None), ('linear', 'fp32')])\n",
      "2024-02-02 08:08:18 [INFO] *** Ending tuning process due to no quantifiable op left.\n",
      "2024-02-02 08:08:18 [INFO] *** Start basic tuning.\n",
      "2024-02-02 08:08:18 [INFO] Execute the tuning process due to detect the evaluation function.\n",
      "2024-02-02 08:08:18 [INFO] Adaptor has 5 recipes.\n",
      "2024-02-02 08:08:18 [INFO] 0 recipes specified by user.\n",
      "2024-02-02 08:08:18 [INFO] 3 recipes require future tuning.\n",
      "2024-02-02 08:08:18 [WARNING] [Strategy] Please install `mpi4py` correctly if using distributed tuning; otherwise, ignore this warning.\n",
      "2024-02-02 08:08:18 [INFO] FP32 baseline is: [Accuracy: 88.1250, Duration (seconds): 1.8365]\n",
      "2024-02-02 08:08:18 [WARNING] Find evaluated tuning config, skip.\n",
      "2024-02-02 08:08:18 [INFO] Apply all recipes.\n",
      "2024-02-02 08:08:18 [INFO] Fx trace of the entire model failed, We will conduct auto quantization\n",
      "2024-02-02 08:08:20 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-02-02 08:08:20 [INFO] +-----------------+----------+---------+\n",
      "2024-02-02 08:08:20 [INFO] |     Op Type     |  Total   |   INT8  |\n",
      "2024-02-02 08:08:20 [INFO] +-----------------+----------+---------+\n",
      "2024-02-02 08:08:20 [INFO] |    Embedding    |    2     |    2    |\n",
      "2024-02-02 08:08:20 [INFO] |      Linear     |    37    |    37   |\n",
      "2024-02-02 08:08:20 [INFO] +-----------------+----------+---------+\n",
      "2024-02-02 08:08:20 [INFO] Pass quantize model elapsed time: 1494.61 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b93a24b82c4776883ead8e8d54c6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`squad_v2_format` parameter not provided to QuestionAnsweringEvaluator.compute(). Automatically inferred `squad_v2_format` as False.\n",
      "2024-02-02 08:08:21 [INFO] Tune 4 result is: [Accuracy (int8|fp32): 82.0486|88.1250, Duration (seconds) (int8|fp32): 1.6091|1.8365], Best tune result is: n/a\n",
      "2024-02-02 08:08:21 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2024-02-02 08:08:21 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:21 [INFO] |     Info Type      | Baseline | Tune 4 result | Best tune result |\n",
      "2024-02-02 08:08:21 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:21 [INFO] |      Accuracy      | 88.1250  |    82.0486    |       n/a        |\n",
      "2024-02-02 08:08:21 [INFO] | Duration (seconds) | 1.8365   |    1.6091     |       n/a        |\n",
      "2024-02-02 08:08:21 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:21 [INFO] Save tuning history to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/./history.snapshot.\n",
      "2024-02-02 08:08:21 [INFO] Apply recipe one by one.\n",
      "2024-02-02 08:08:21 [INFO] Start to fallback op to bf16 by blocks\n",
      "2024-02-02 08:08:22 [INFO] Fx trace of the entire model failed, We will conduct auto quantization\n",
      "2024-02-02 08:08:23 [INFO] Convert operators to bfloat16\n",
      "2024-02-02 08:08:23 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-02-02 08:08:23 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:23 [INFO] |   Op Type   | Total  | INT8 |  BF16  |\n",
      "2024-02-02 08:08:23 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:23 [INFO] |  Embedding  |   2    |  2   |   0    |\n",
      "2024-02-02 08:08:23 [INFO] |    Linear   |   37   |  35  |   2    |\n",
      "2024-02-02 08:08:23 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:23 [INFO] Pass quantize model elapsed time: 1563.8 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b839d3b93f42a2882bcd3db6037031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`squad_v2_format` parameter not provided to QuestionAnsweringEvaluator.compute(). Automatically inferred `squad_v2_format` as False.\n",
      "2024-02-02 08:08:25 [INFO] Tune 5 result is: [Accuracy (int8|fp32): 82.3611|88.1250, Duration (seconds) (int8|fp32): 1.6219|1.8365], Best tune result is: n/a\n",
      "2024-02-02 08:08:25 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2024-02-02 08:08:25 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:25 [INFO] |     Info Type      | Baseline | Tune 5 result | Best tune result |\n",
      "2024-02-02 08:08:25 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:25 [INFO] |      Accuracy      | 88.1250  |    82.3611    |       n/a        |\n",
      "2024-02-02 08:08:25 [INFO] | Duration (seconds) | 1.8365   |    1.6219     |       n/a        |\n",
      "2024-02-02 08:08:25 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:25 [INFO] Save tuning history to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/./history.snapshot.\n",
      "2024-02-02 08:08:25 [INFO] Fx trace of the entire model failed, We will conduct auto quantization\n",
      "2024-02-02 08:08:26 [INFO] Convert operators to bfloat16\n",
      "2024-02-02 08:08:26 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-02-02 08:08:26 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:26 [INFO] |   Op Type   | Total  | INT8 |  BF16  |\n",
      "2024-02-02 08:08:26 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:26 [INFO] |  Embedding  |   2    |  2   |   0    |\n",
      "2024-02-02 08:08:26 [INFO] |    Linear   |   37   |  33  |   4    |\n",
      "2024-02-02 08:08:26 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:26 [INFO] Pass quantize model elapsed time: 1364.82 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b282a204f89f48a6b08b2bc349ffeac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`squad_v2_format` parameter not provided to QuestionAnsweringEvaluator.compute(). Automatically inferred `squad_v2_format` as False.\n",
      "2024-02-02 08:08:28 [INFO] Tune 6 result is: [Accuracy (int8|fp32): 83.1944|88.1250, Duration (seconds) (int8|fp32): 1.7554|1.8365], Best tune result is: n/a\n",
      "2024-02-02 08:08:28 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2024-02-02 08:08:28 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:28 [INFO] |     Info Type      | Baseline | Tune 6 result | Best tune result |\n",
      "2024-02-02 08:08:28 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:28 [INFO] |      Accuracy      | 88.1250  |    83.1944    |       n/a        |\n",
      "2024-02-02 08:08:28 [INFO] | Duration (seconds) | 1.8365   |    1.7554     |       n/a        |\n",
      "2024-02-02 08:08:28 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:28 [INFO] Save tuning history to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/./history.snapshot.\n",
      "2024-02-02 08:08:28 [INFO] Fx trace of the entire model failed, We will conduct auto quantization\n",
      "2024-02-02 08:08:29 [INFO] Convert operators to bfloat16\n",
      "2024-02-02 08:08:29 [INFO] |******Mixed Precision Statistics******|\n",
      "2024-02-02 08:08:29 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:29 [INFO] |   Op Type   | Total  | INT8 |  BF16  |\n",
      "2024-02-02 08:08:29 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:29 [INFO] |  Embedding  |   2    |  2   |   0    |\n",
      "2024-02-02 08:08:29 [INFO] |    Linear   |   37   |  31  |   6    |\n",
      "2024-02-02 08:08:29 [INFO] +-------------+--------+------+--------+\n",
      "2024-02-02 08:08:29 [INFO] Pass quantize model elapsed time: 1279.12 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "091f7b7d17754da78d3659cd4977553d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`squad_v2_format` parameter not provided to QuestionAnsweringEvaluator.compute(). Automatically inferred `squad_v2_format` as False.\n",
      "2024-02-02 08:08:31 [INFO] Tune 7 result is: [Accuracy (int8|fp32): 86.2946|88.1250, Duration (seconds) (int8|fp32): 1.8099|1.8365], Best tune result is: [Accuracy: 86.2946, Duration (seconds): 1.8099]\n",
      "2024-02-02 08:08:31 [INFO] |**********************Tune Result Statistics**********************|\n",
      "2024-02-02 08:08:31 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:31 [INFO] |     Info Type      | Baseline | Tune 7 result | Best tune result |\n",
      "2024-02-02 08:08:31 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:31 [INFO] |      Accuracy      | 88.1250  |    86.2946    |     86.2946      |\n",
      "2024-02-02 08:08:31 [INFO] | Duration (seconds) | 1.8365   |    1.8099     |     1.8099       |\n",
      "2024-02-02 08:08:31 [INFO] +--------------------+----------+---------------+------------------+\n",
      "2024-02-02 08:08:31 [INFO] [Strategy] Found a model that meets the accuracy requirements.\n",
      "2024-02-02 08:08:31 [INFO] Save tuning history to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/./history.snapshot.\n",
      "2024-02-02 08:08:31 [INFO] Specified timeout or max trials is reached! Found a quantized model which meet accuracy goal. Exit.\n",
      "2024-02-02 08:08:31 [INFO] Save deploy yaml to /home/uad6b15e0ae3d5e407195ab5f044a50f/ai-innovation-bridge/workshops/ai-workloads-with-huggingface/nc_workspace/2024-02-02_08-07-59/deploy.yaml\n",
      "Model weights saved to dynamic_quantization/pytorch_model.bin\n",
      "Configuration saved in dynamic_quantization/inc_config.json\n"
     ]
    }
   ],
   "source": [
    "quantizer = INCQuantizer.from_pretrained(model, eval_fn=eval_fn)\n",
    "quantizer.quantize(quantization_config=quantization_config, save_directory=\"dynamic_quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab63e8-e951-47b7-817d-69439c31d55a",
   "metadata": {},
   "source": [
    "# Conclusion and Discussion\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "In this workshop, we've successfully navigated the process of dynamically quantizing a model using the Optimum Intel library. We learned the importance of balancing accuracy and computational efficiency and gained hands-on experience in configuring and applying dynamic quantization to a DistilBERT model#.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The skills and knowledge acquired in this session are critical for developers looking to optimize NLP models for production environments, especially where resource constraints are a consideration. Understanding the nuances of model quantization, particularly in the context of dynamic vs. static approaches, empowers developers to make informed decisions about deploying AI models in various scenarios.\n",
    "\n",
    "As we continue to push the boundaries of AI efficiency, the ability to effectively quantize models while maintaining their performance will be an invaluable asset in the toolkit of any AI practitioner."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
