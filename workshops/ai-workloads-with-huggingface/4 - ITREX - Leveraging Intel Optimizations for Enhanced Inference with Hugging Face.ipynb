{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bebdcd72-b25b-4f60-9f87-5a7f75df466c",
   "metadata": {},
   "source": [
    "# ITREX - Leveraging Intel Optimizations for Enhanced Inference with Hugging Face\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*AfoKgyTN6l7xNg30GmbsLg.png\" alt=\"Alt Text\" style=\"width: 800px;\"/>\n",
    "\n",
    "Welcome to this developer-focused workshop, where we explore the integration of Intel extensions with Hugging Face models for optimized inference. The goal of this notebook is to demonstrate how developers can use Intel's extensions to achieve efficient and performant inference in production applications.\n",
    "\n",
    "## Why Intel Optimizations Matter\n",
    "\n",
    "In the realm of machine learning, particularly in NLP, the ability to perform efficient and speedy inference is crucial. By using the Intel extension for Transformers, we can load models directly from the Hugging Face Hub, like the \"Intel/neural-chat-7b-v1-1\" model, and optimize them for high-performance inference.\n",
    "\n",
    "### Key Learning Points\n",
    "\n",
    "- **Model Optimization**: Learn how to load and optimize Hugging Face models using Intel's neural compressor and extension APIs.\n",
    "- **Streaming Output**: We'll use the TextStreamer functionality from Hugging Face Transformers to deliver a constant stream of tokens, enhancing the user experience by avoiding large text dumps.\n",
    "- **Intel's Neural Chat Model**: Explore the \"Intel/neural-chat-7b-v1-1\" model, fine-tuned on Gaudi 2 processors, to understand its capabilities in generating text based on input prompts.\n",
    "- **Practical Application**: Understand how these optimizations can be applied in real-world scenarios to deliver performant inference with minimal code.\n",
    "\n",
    "By the end of this notebook, you'll have a practical understanding of how to apply Intel's optimizations to Hugging Face models for efficient inference.\n",
    "\n",
    "Let's dive in and explore the power of optimized model inference!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175e5202-27ad-47a8-9906-e831ad51db6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ":: WARNING: setvars.sh has already been run. Skipping re-execution.\n",
      "   To force a re-execution of setvars.sh, use the '--force' option.\n",
      "   Using '--force' can result in excessive use of your environment variables.\n",
      "  \n",
      "usage: source setvars.sh [--force] [--config=file] [--help] [...]\n",
      "  --force        Force setvars.sh to re-run, doing so may overload environment.\n",
      "  --config=file  Customize env vars using a setvars.sh configuration file.\n",
      "  --help         Display this help message and exit.\n",
      "  ...            Additional args are passed to individual env/vars.sh scripts\n",
      "                 and should follow this script's arguments.\n",
      "  \n",
      "  Some POSIX shells do not accept command-line options. In that case, you can pass\n",
      "  command-line options via the SETVARS_ARGS environment variable. For example:\n",
      "  \n",
      "  $ SETVARS_ARGS=\"ia32 --config=config.txt\" ; export SETVARS_ARGS\n",
      "  $ . path/to/setvars.sh\n",
      "  \n",
      "  The SETVARS_ARGS environment variable is cleared on exiting setvars.sh.\n",
      "  \n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers==4.35.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.35.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.35.2) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.2) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.35.2) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.35.2) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.35.2) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.2) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.2) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.2) (2023.7.22)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: intel_extension_for_transformers==1.2.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (1.2.2)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel_extension_for_transformers==1.2.2) (23.1)\n",
      "Requirement already satisfied: numpy in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel_extension_for_transformers==1.2.2) (1.24.3)\n",
      "Requirement already satisfied: schema in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from intel_extension_for_transformers==1.2.2) (0.7.5)\n",
      "Requirement already satisfied: pyyaml in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel_extension_for_transformers==1.2.2) (6.0)\n",
      "Requirement already satisfied: neural-compressor in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from intel_extension_for_transformers==1.2.2) (2.4.1)\n",
      "Collecting transformers==4.34.1 (from intel_extension_for_transformers==1.2.2)\n",
      "  Using cached transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "Requirement already satisfied: filelock in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.34.1->intel_extension_for_transformers==1.2.2) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.34.1->intel_extension_for_transformers==1.2.2) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.34.1->intel_extension_for_transformers==1.2.2) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.34.1->intel_extension_for_transformers==1.2.2) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.34.1->intel_extension_for_transformers==1.2.2) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from transformers==4.34.1->intel_extension_for_transformers==1.2.2) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.34.1->intel_extension_for_transformers==1.2.2) (4.65.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (1.2.14)\n",
      "Requirement already satisfied: opencv-python-headless in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (4.9.0.80)\n",
      "Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (2.0.3)\n",
      "Requirement already satisfied: Pillow in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (10.0.0)\n",
      "Requirement already satisfied: prettytable in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (3.9.0)\n",
      "Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (9.0.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (1.2.2)\n",
      "Requirement already satisfied: pycocotools in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from neural-compressor->intel_extension_for_transformers==1.2.2) (2.0.7)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from schema->intel_extension_for_transformers==1.2.2) (21.6.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from deprecated>=1.2.13->neural-compressor->intel_extension_for_transformers==1.2.2) (1.16.0)\n",
      "Requirement already satisfied: fsspec in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1->intel_extension_for_transformers==1.2.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.1->intel_extension_for_transformers==1.2.2) (4.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->neural-compressor->intel_extension_for_transformers==1.2.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->neural-compressor->intel_extension_for_transformers==1.2.2) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->neural-compressor->intel_extension_for_transformers==1.2.2) (2023.3)\n",
      "Requirement already satisfied: wcwidth in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from prettytable->neural-compressor->intel_extension_for_transformers==1.2.2) (0.2.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pycocotools->neural-compressor->intel_extension_for_transformers==1.2.2) (3.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.34.1->intel_extension_for_transformers==1.2.2) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.34.1->intel_extension_for_transformers==1.2.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.34.1->intel_extension_for_transformers==1.2.2) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.34.1->intel_extension_for_transformers==1.2.2) (2023.7.22)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from scikit-learn->neural-compressor->intel_extension_for_transformers==1.2.2) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from scikit-learn->neural-compressor->intel_extension_for_transformers==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from scikit-learn->neural-compressor->intel_extension_for_transformers==1.2.2) (3.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers==1.2.2) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers==1.2.2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers==1.2.2) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers==1.2.2) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from matplotlib>=2.1.0->pycocotools->neural-compressor->intel_extension_for_transformers==1.2.2) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->neural-compressor->intel_extension_for_transformers==1.2.2) (1.16.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed transformers-4.34.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: intel_extension_for_pytorch==2.1.100 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (2.1.100)\n",
      "Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel_extension_for_pytorch==2.1.100) (5.9.0)\n",
      "Requirement already satisfied: numpy in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel_extension_for_pytorch==2.1.100) (1.24.3)\n",
      "Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from intel_extension_for_pytorch==2.1.100) (23.1)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (4.65.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: einops in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (0.7.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: neural_speed==0.2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (0.2)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torch==2.1.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (1.12)\n",
      "Requirement already satisfied: networkx in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from torch==2.1.1) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.1) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from jinja2->torch==2.1.1) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages (from sympy->torch==2.1.1) (1.3.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/uad6b15e0ae3d5e407195ab5f044a50f/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!source /opt/intel/oneapi/setvars.sh #comment out if not running on Intel Developer Cloud Jupyter\n",
    "!pip install transformers==4.35.2\n",
    "!pip install intel_extension_for_transformers==1.2.2\n",
    "!pip install intel_extension_for_pytorch==2.1.100\n",
    "!pip install tqdm\n",
    "!pip install einops\n",
    "!pip install neural_speed==0.2\n",
    "!pip install torch==2.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e56fd8-e677-4823-a511-149400b1ab78",
   "metadata": {},
   "source": [
    "#### Importing Required Libraries\n",
    "\n",
    "This cell sets the foundation for our model optimization and text generation tasks. We import:\n",
    "- `AutoTokenizer` and `TextStreamer` from Hugging Face's `transformers` library, crucial for tokenizing our input text and streaming the model's output.\n",
    "- `AutoModelForCausalLM` from `intel_extension_for_transformers`, which is a specialized version of the model class optimized for Intel hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc37ad1-91cc-416e-b2a9-d9a95338178d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TextStreamer\n",
    "from intel_extension_for_transformers.transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e1cd5-0572-4627-b35a-0245a2acec36",
   "metadata": {},
   "source": [
    "#### Model and Prompt Setup\n",
    "\n",
    "Here, we specify the model and the initial text prompt for our text generation task.\n",
    "- `model_name`: We set this to \"Intel/neural-chat-7b-v1-1\", a model fine-tuned on Intel's hardware, available on the Hugging Face model hub.\n",
    "- `prompt`: This is our starting text for the model to generate from, setting the context for the text generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f36c711-5c3f-4480-8edc-077afeb8a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Intel/neural-chat-7b-v1-1\"     # Hugging Face model_id or local model\n",
    "prompt = \"Once upon a time, there existed a fisherman at sea,\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90516c0d-2462-4756-b740-7197906d3077",
   "metadata": {},
   "source": [
    "#### Tokenizer Initialization and Input Preparation\n",
    "\n",
    "In this cell, we initialize the tokenizer with our chosen model and prepare our input text for the model.\n",
    "- `tokenizer`: Loaded with the `AutoTokenizer.from_pretrained` method, tailored for our specific model.\n",
    "- `inputs`: The prompt is tokenized to be fed into the model.\n",
    "- `streamer`: An instance of `TextStreamer` is created with our tokenizer, enabling efficient and user-friendly text generation output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f6a306-745f-4951-8597-e32e55c47d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "streamer = TextStreamer(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503933d0-c181-44dd-87d9-0e643ace3145",
   "metadata": {},
   "source": [
    "#### Model Loading and Text Generation\n",
    "\n",
    "This is where the action happens:\n",
    "- We load our model using `AutoModelForCausalLM.from_pretrained`, with `load_in_4bit=True` to enable optimized inference.\n",
    "- The model's `generate` function is called with the `streamer` parameter, which enables streaming output of the text. We set `max_new_tokens` to 300 to control the length of the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b58d03-6d3c-4b3b-86b9-9ab29bc70d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-02 08:05:37 [INFO] CPU device is used.\n",
      "2024-02-02 08:05:37 [INFO] Applying Weight Only Quantization.\n",
      "2024-02-02 08:05:37 [INFO] Using LLM runtime.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime_outs/ne_mpt_q_int4_jblas_cint8_g32.bin existed, will use cache file. Otherwise please remove the file\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de5d005-a591-429c-8cac-4137e7b60198",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there existed a fisherman at sea, who had "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.cpp: loading model from runtime_outs/ne_mpt_q_int4_jblas_cint8_g32.bin\n",
      "init: n_vocab    = 50279\n",
      "init: n_embd     = 4096\n",
      "init: n_mult     = 4096\n",
      "init: n_head     = 32\n",
      "init: n_layer    = 32\n",
      "init: n_rot      = 32\n",
      "init: n_ff       = 16384\n",
      "init: n_parts    = 1\n",
      "load: ne ctx size = 4737.55 MB\n",
      "load: mem required  = 12929.55 MB (+ memory per state)\n",
      "..................................................................................................\n",
      "model_init_from_file: support_jblas_kv = 1\n",
      "model_init_from_file: kv self size =  276.00 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "been fishing for a long time. He had fished in many different places, but he had never fished in this particular place. He had heard stories about the fish that were in this place, but he had never seen them himself.\n",
      "\n",
      "One day, he decided to go fishing in this place. He had heard that there were a lot of fish in this place, so he was excited. He had never fished in this place before, so he was a little nervous. He had heard that the fish were very big, so he was excited.\n",
      "\n",
      "He went out to sea, and he started fishing. He caught a lot of fish, and he was very happy. He had never fished in this place before, but he had heard about it, and he was glad that he had decided to go.\n",
      "\n",
      "The fisherman was very happy with his catch, and he decided to go back to the same place the next day. He was very excited to go back, because he had heard that there were even more fish in this place. He was very happy with his catch, and he was glad that he had decided to go.\n",
      "\n",
      "The fisherman went back to the same place the next day, and he caught even more fish. He was very happy with his catch, and he was glad that he had decided to go. He had never fished in this place before, but he had heard about it, and he was glad that he\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[10758,\n",
       "  2220,\n",
       "  247,\n",
       "  673,\n",
       "  13,\n",
       "  627,\n",
       "  13164,\n",
       "  247,\n",
       "  27633,\n",
       "  1342,\n",
       "  387,\n",
       "  6150,\n",
       "  13,\n",
       "  665,\n",
       "  574,\n",
       "  644,\n",
       "  15133,\n",
       "  323,\n",
       "  247,\n",
       "  1048,\n",
       "  673,\n",
       "  15,\n",
       "  754,\n",
       "  574,\n",
       "  269,\n",
       "  1428,\n",
       "  275,\n",
       "  1142,\n",
       "  1027,\n",
       "  5053,\n",
       "  13,\n",
       "  533,\n",
       "  344,\n",
       "  574,\n",
       "  1620,\n",
       "  269,\n",
       "  1428,\n",
       "  275,\n",
       "  436,\n",
       "  1798,\n",
       "  1659,\n",
       "  15,\n",
       "  754,\n",
       "  574,\n",
       "  3735,\n",
       "  6281,\n",
       "  670,\n",
       "  253,\n",
       "  6773,\n",
       "  326,\n",
       "  497,\n",
       "  275,\n",
       "  436,\n",
       "  1659,\n",
       "  13,\n",
       "  533,\n",
       "  344,\n",
       "  574,\n",
       "  1620,\n",
       "  2326,\n",
       "  731,\n",
       "  2994,\n",
       "  15,\n",
       "  187,\n",
       "  187,\n",
       "  4041,\n",
       "  1388,\n",
       "  13,\n",
       "  344,\n",
       "  4425,\n",
       "  281,\n",
       "  564,\n",
       "  15133,\n",
       "  275,\n",
       "  436,\n",
       "  1659,\n",
       "  15,\n",
       "  754,\n",
       "  574,\n",
       "  3735,\n",
       "  326,\n",
       "  627,\n",
       "  497,\n",
       "  247,\n",
       "  2257,\n",
       "  273,\n",
       "  6773,\n",
       "  275,\n",
       "  436,\n",
       "  1659,\n",
       "  13,\n",
       "  594,\n",
       "  344,\n",
       "  369,\n",
       "  9049,\n",
       "  15,\n",
       "  754,\n",
       "  574,\n",
       "  1620,\n",
       "  269,\n",
       "  1428,\n",
       "  275,\n",
       "  436,\n",
       "  1659,\n",
       "  1078,\n",
       "  13,\n",
       "  594,\n",
       "  344,\n",
       "  369,\n",
       "  247,\n",
       "  1652,\n",
       "  11219,\n",
       "  15,\n",
       "  754,\n",
       "  574,\n",
       "  3735,\n",
       "  326,\n",
       "  253,\n",
       "  6773,\n",
       "  497,\n",
       "  1077,\n",
       "  1943,\n",
       "  13,\n",
       "  594,\n",
       "  344,\n",
       "  369,\n",
       "  9049,\n",
       "  15,\n",
       "  187,\n",
       "  187,\n",
       "  1328,\n",
       "  2427,\n",
       "  562,\n",
       "  281,\n",
       "  6150,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  3053,\n",
       "  15133,\n",
       "  15,\n",
       "  754,\n",
       "  7270,\n",
       "  247,\n",
       "  2257,\n",
       "  273,\n",
       "  6773,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  369,\n",
       "  1077,\n",
       "  5211,\n",
       "  15,\n",
       "  754,\n",
       "  574,\n",
       "  1620,\n",
       "  269,\n",
       "  1428,\n",
       "  275,\n",
       "  436,\n",
       "  1659,\n",
       "  1078,\n",
       "  13,\n",
       "  533,\n",
       "  344,\n",
       "  574,\n",
       "  3735,\n",
       "  670,\n",
       "  352,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  369,\n",
       "  9995,\n",
       "  326,\n",
       "  344,\n",
       "  574,\n",
       "  4425,\n",
       "  281,\n",
       "  564,\n",
       "  15,\n",
       "  187,\n",
       "  187,\n",
       "  510,\n",
       "  27633,\n",
       "  1342,\n",
       "  369,\n",
       "  1077,\n",
       "  5211,\n",
       "  342,\n",
       "  521,\n",
       "  5834,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  4425,\n",
       "  281,\n",
       "  564,\n",
       "  896,\n",
       "  281,\n",
       "  253,\n",
       "  1072,\n",
       "  1659,\n",
       "  253,\n",
       "  1735,\n",
       "  1388,\n",
       "  15,\n",
       "  754,\n",
       "  369,\n",
       "  1077,\n",
       "  9049,\n",
       "  281,\n",
       "  564,\n",
       "  896,\n",
       "  13,\n",
       "  984,\n",
       "  344,\n",
       "  574,\n",
       "  3735,\n",
       "  326,\n",
       "  627,\n",
       "  497,\n",
       "  1014,\n",
       "  625,\n",
       "  6773,\n",
       "  275,\n",
       "  436,\n",
       "  1659,\n",
       "  15,\n",
       "  754,\n",
       "  369,\n",
       "  1077,\n",
       "  5211,\n",
       "  342,\n",
       "  521,\n",
       "  5834,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  369,\n",
       "  9995,\n",
       "  326,\n",
       "  344,\n",
       "  574,\n",
       "  4425,\n",
       "  281,\n",
       "  564,\n",
       "  15,\n",
       "  187,\n",
       "  187,\n",
       "  510,\n",
       "  27633,\n",
       "  1342,\n",
       "  2427,\n",
       "  896,\n",
       "  281,\n",
       "  253,\n",
       "  1072,\n",
       "  1659,\n",
       "  253,\n",
       "  1735,\n",
       "  1388,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  7270,\n",
       "  1014,\n",
       "  625,\n",
       "  6773,\n",
       "  15,\n",
       "  754,\n",
       "  369,\n",
       "  1077,\n",
       "  5211,\n",
       "  342,\n",
       "  521,\n",
       "  5834,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  369,\n",
       "  9995,\n",
       "  326,\n",
       "  344,\n",
       "  574,\n",
       "  4425,\n",
       "  281,\n",
       "  564,\n",
       "  15,\n",
       "  754,\n",
       "  574,\n",
       "  1620,\n",
       "  269,\n",
       "  1428,\n",
       "  275,\n",
       "  436,\n",
       "  1659,\n",
       "  1078,\n",
       "  13,\n",
       "  533,\n",
       "  344,\n",
       "  574,\n",
       "  3735,\n",
       "  670,\n",
       "  352,\n",
       "  13,\n",
       "  285,\n",
       "  344,\n",
       "  369,\n",
       "  9995,\n",
       "  326,\n",
       "  344]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(inputs, streamer=streamer, max_new_tokens=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588dfd27-b61b-4e3a-9445-83277b0695da",
   "metadata": {},
   "source": [
    "# Conclusion and Discussion\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "This workshop demonstrated the practical application of Intel optimizations in conjunction with Hugging Face's powerful Transformers library. We explored the nuances of model loading, tokenization, and efficient text generation using Intel's neural compressor and extension APIs.\n",
    "\n",
    "### Discussion\n",
    "\n",
    "The skills and knowledge gained here are essential for developers looking to implement optimized NLP models in production environments. The ability to generate text in a streamed manner and leverage Intel's hardware optimizations showcases the potential for building responsive and efficient AI-powered applications.\n",
    "\n",
    "As we continue to advance in the field of AI, understanding and applying such optimizations will be crucial for developers to stay ahead in creating high-performance, scalable, and user-friendly applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
